this paper proposes formulating zipf's meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. the proposed formulation quantifies meaning counts indirectly as contextual diversity, which is based on directions of contextualized word vectors obtained by a language model (lm). this way of formulation gives a new interpretation to the law and also enables us to examine it for a wider variety of words and corpora that the previous studies have explored. in addition, this paper shows that the law becomes unobservable when the size of the used lm is small and that conventional lms that predict the next token require much more parameters than masked lms to be able to observe the law.
this paper proposes formulating zipf's meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. the proposed formulation quantifies meaning counts indirectly as contextual diversity, which is based on directions of contextualized word vectors obtained by a language model (lm). this way of formulation gives a new interpretation to the law and also enables us to examine it for a wider variety of words and corpora that the previous studies have explored. in addition, this paper shows that the law becomes unobservable when the size of the used lm is small and that conventional lms that predict the next token require much more parameters than masked lms to be able to observe the law.
this paper proposes formulating zipf's meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. the proposed formulation quantifies meaning counts indirectly as contextual diversity, which is based on directions of contextualized word vectors obtained by a language model (lm). this way of formulation gives a new interpretation to the law and also enables us to examine it for a wider variety of words and corpora that the previous studies have explored. in addition, this paper shows that the law becomes unobservable when the size of the used lm is small and that conventional lms that predict the next token require much more parameters than masked lms to be able to observe the law.
this paper proposes formulating zipf's meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. the proposed formulation quantifies meaning counts indirectly as contextual diversity, which is based on directions of contextualized word vectors obtained by a language model (lm). this way of formulation gives a new interpretation to the law and also enables us to examine it for a wider variety of words and corpora that the previous studies have explored. in addition, this paper shows that the law becomes unobservable when the size of the used lm is small and that conventional lms that predict the next token require much more parameters than masked lms to be able to observe the law.
this paper proposes formulating zipf's meaning-frequency law, the power law between word frequency and the number of meanings, as a relationship between word frequency and contextual diversity. the proposed formulation quantifies meaning counts indirectly as contextual diversity, which is based on directions of contextualized word vectors obtained by a language model (lm). this way of formulation gives a new interpretation to the law and also enables us to examine it for a wider variety of words and corpora that the previous studies have explored. in addition, this paper shows that the law becomes unobservable when the size of the used lm is small and that conventional lms that predict the next token require much more parameters than masked lms to be able to observe the law.
